{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "\n",
    "# Step 1: Load Pre-trained CNN\n",
    "base_model = ResNet50(weights='imagenet')\n",
    "# We'll use the output of the layer just before the final dense layer (usually named 'avg_pool' for ResNet)\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('avg_pool').output)\n",
    "\n",
    "# Step 2: Preprocess the Image\n",
    "def preprocess_image_pillow(img_path):\n",
    "    img = PILImage.open(img_path)\n",
    "    img = img.resize((224, 224))  # Resize image to 224x224\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # If the image has an alpha channel, we should remove it\n",
    "    if img_array.shape[2] == 4:\n",
    "        img_array = img_array[:, :, :3]\n",
    "\n",
    "    # Convert the image array to float and rescale it\n",
    "    img_array = img_array.astype(np.float32)\n",
    "\n",
    "    # Preprocess the image for the model (ResNet in this case)\n",
    "    # This step depends on the pre-trained model's expected input\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)  # Ensure you use the correct preprocess_input function for your model\n",
    "\n",
    "    return img_array\n",
    "\n",
    "# Step 3: Extract Features\n",
    "def extract_features(img_path, model):\n",
    "    preprocessed_image = preprocess_image_pillow(img_path)\n",
    "    features = model.predict(preprocessed_image)\n",
    "    flattened_features = features.flatten()  # Flatten the features to a 1D array\n",
    "    return flattened_features\n",
    "\n",
    "# Step 4: Normalize Features\n",
    "def normalize_features(features):\n",
    "    # Normalize feature vector (L2 norm)\n",
    "    normalized_features = features / np.linalg.norm(features)\n",
    "    return normalized_features\n",
    "\n",
    "# Step 5: Reduce Dimensionality\n",
    "def reduce_dimensionality(features, n_components=300):\n",
    "    # Initialize PCA object to reduce to n_components dimensions\n",
    "    pca = PCA(n_components=n_components)\n",
    "    features = np.array(features)\n",
    "    pca.fit(features)\n",
    "    reduced_features = pca.transform(features)\n",
    "    return reduced_features\n",
    "\n",
    "\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def cosine_similarity(vec_a, vec_b):\n",
    "    similarity = np.dot(vec_a, vec_b) / (norm(vec_a) * norm(vec_b))\n",
    "    return similarity\n",
    "\n",
    "\n",
    "\n",
    "# Sample Usage\n",
    "# Assuming 'image_path' is the path to the image file\n",
    "mouse1 = r'C:\\Users\\ayhan\\Desktop\\Smart-Shopper-Recommendation-Engine\\mouse1.jpg'\n",
    "mouse2 = r'C:\\Users\\ayhan\\Desktop\\Smart-Shopper-Recommendation-Engine\\mouse2.jpg'\n",
    "klavye = r'C:\\Users\\ayhan\\Desktop\\Smart-Shopper-Recommendation-Engine\\klavye.jpg'\n",
    "laptop = r'C:\\Users\\ayhan\\Desktop\\Smart-Shopper-Recommendation-Engine\\laptop.jpg'\n",
    "nutella = r'C:\\Users\\ayhan\\Desktop\\Smart-Shopper-Recommendation-Engine\\nutella.jpg'\n",
    "\n",
    "features1 = extract_features(mouse1, model)\n",
    "normalized_features1 = normalize_features(features1)\n",
    "features2 = extract_features(mouse2, model)\n",
    "normalized_features2 = normalize_features(features2)\n",
    "features3 = extract_features(klavye, model)\n",
    "normalized_features3 = normalize_features(features3)\n",
    "features4 = extract_features(laptop, model)\n",
    "normalized_features4 = normalize_features(features4)\n",
    "features5 = extract_features(nutella, model)\n",
    "normalized_features5 = normalize_features(features5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity with similar image: 0.7657989\n",
      "Similarity with irrelevant image: 0.34152448\n",
      "Similarity with nutella image: 0.36515915\n"
     ]
    }
   ],
   "source": [
    "### PERFORM SIMILARIY SEARCH BTW IMAGES\n",
    "\n",
    "similarity_with_similar = cosine_similarity(normalized_features1, normalized_features2)\n",
    "similarity_with_irrelevant = cosine_similarity(normalized_features1, normalized_features3)\n",
    "similarity_with_irrelevant2 = cosine_similarity(normalized_features1, normalized_features4)\n",
    "\n",
    "print(\"Similarity with similar image:\", similarity_with_similar)\n",
    "print(\"Similarity with irrelevant image:\", similarity_with_irrelevant)\n",
    "print(\"Similarity with nutella image:\", cosine_similarity(normalized_features1, normalized_features5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shopping_recommender_engine",
   "language": "python",
   "name": "shopping_recommender_engine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
